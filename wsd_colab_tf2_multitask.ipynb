{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"wsd_colab_tf2_multitask.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"code","metadata":{"id":"DRqC8EU4FA2d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e086b352-8155-4a2e-e6de-b4ef3fc7a14a","executionInfo":{"status":"ok","timestamp":1585767218554,"user_tz":-120,"elapsed":764,"user":{"displayName":"emanuele alessi","photoUrl":"","userId":"08652787951056062162"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Oz6yz9QuZQqZ","colab":{}},"source":["import numpy as np\n","import xml.etree.ElementTree as ET"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cRgJyXeiZQqh","colab":{}},"source":["f = open('drive/My Drive/AFC/embeddings/glove.6B.100d.txt', 'r', encoding='utf8')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7SzMyNYJZQqm","colab":{}},"source":["lines = f.readlines()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bcaJZFKhZQqr","colab":{}},"source":["word2index = {}\n","embeddings = np.zeros(shape=(len(lines) + 1, len(lines[0].split()[1:])), dtype=np.float32)\n","for idx, line in enumerate(lines):\n","    line = line.split()\n","    word2index[line[0]] = len(word2index) + 1\n","    embeddings[idx + 1] = np.array(line[1:], dtype=np.float32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XdhfoV9jUyhv","colab":{}},"source":["root = ET.parse('drive/My Drive/AFC/dataset/semcor.data.xml').getroot()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pFtuxV1bZQq0","colab":{}},"source":["#loading training set\n","pos2index = {}\n","lemma2index = {'unk': 1}\n","f = open('drive/My Drive/AFC/dataset/semcor.gold.key.bnids.txt', 'r', encoding='utf8')\n","sentences = []\n","lemmas = []\n","pos = []\n","for sentence in root.findall('text/sentence'):\n","    s = []\n","    l = []\n","    p = []\n","    for word in sentence:\n","        w = word.text.lower()\n","        lemma = word.attrib['lemma'].lower()\n","        tag = word.attrib['pos'].lower()\n","        s.append(word2index[w]) if w in word2index else s.append(word2index['unk'])\n","        if lemma not in lemma2index:\n","          lemma2index[lemma] = len(lemma2index) + 1\n","        l.append(lemma2index[lemma])\n","        if tag not in pos2index:\n","            pos2index[tag] = len(pos2index) + 1\n","        p.append(pos2index[tag])\n","\n","    sentences.append(s)\n","    lemmas.append(l)\n","    pos.append(p)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VxyNeXAdZQq6","colab":{}},"source":["root = ET.parse('drive/My Drive/AFC/dataset/ALL.data.xml').getroot()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XwFdaCVyZQq_","colab":{}},"source":["#loading test set\n","f = open('drive/My Drive/AFC/dataset/ALL.gold.key.bnids.txt', 'r', encoding='utf8')\n","test = {}\n","for sentence in root.findall('text/sentence'):\n","    s = []\n","    l = []\n","    p = []  \n","    dataset = sentence.attrib['id'].split('.')[0]\n","    if dataset not in test:\n","        test[dataset] = []\n","    for word in sentence:\n","        w = word.text.lower()\n","        lemma = word.attrib['lemma'].lower()\n","        tag = word.attrib['pos'].lower()\n","        s.append(word2index[w]) if w in word2index else s.append(word2index['unk'])\n","        l.append(lemma2index[lemma]) if lemma in lemma2index else l.append(lemma2index['unk'])\n","        p.append(pos2index[tag])\n","    test[dataset].append((s, l, p))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lX9ai3FwZQrD","colab":{}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pXwC3jCbFdda","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"75882f19-f146-4d97-d4f4-98ead79c46e2","executionInfo":{"status":"ok","timestamp":1585767239688,"user_tz":-120,"elapsed":16286,"user":{"displayName":"emanuele alessi","photoUrl":"","userId":"08652787951056062162"}}},"source":["tf.__version__"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.1.0'"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hzgH-OzAZQrH","colab":{}},"source":["import tqdm"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Lja1e7pzZQrR","colab":{}},"source":["def accuracy(y_true, y_pred):\n","    assert(len(y_true) == len(y_pred))\n","    c = 0\n","    for true, pred in zip(y_true, y_pred):\n","        if true == pred:\n","            c += 1\n","        \n","    return c / len(y_true)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"F3RLuOS6ZQrd","colab":{}},"source":["batch_size = 16\n","hidden_size = 100\n","\n","word_ids = tf.keras.Input([None], dtype=tf.int32)\n","\n","pretrained_emb = tf.keras.layers.Embedding(embeddings.shape[0], embeddings.shape[1], weights=[embeddings], mask_zero=True, trainable=False)(word_ids)\n","\n","bid = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hidden_size, return_sequences=True))(pretrained_emb)\n","\n","lemmas_scores = tf.keras.layers.Dense(len(lemma2index) + 1)(bid)\n","pos_scores = tf.keras.layers.Dense(len(pos2index) + 1)(bid)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zZEskWWSZQrh","colab":{}},"source":["model = tf.keras.Model(inputs=word_ids, outputs=[lemmas_scores, pos_scores])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZAp04e6PZQrl","colab":{}},"source":["def masked_loss(x):\n","    \n","    def loss(labels, logits):\n","        #print('logits ',logits.get_shape())\n","        #print('labels ', labels.get_shape())\n","        #output_shape = logits.get_shape()\n","        #sequence = tf.count_nonzero(x, axis=-1, dtype=tf.int32)\n","        not_zeros = tf.cast(tf.not_equal(x, 0), tf.int32)\n","        sequence = tf.reduce_sum(not_zeros, axis=-1)\n","        losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n","        mask = tf.sequence_mask(sequence)\n","        #masked_losses = tf.where(mask, losses, tf.zeros_like(losses))\n","        masked_losses = tf.multiply(losses, tf.cast(not_zeros, tf.float32))\n","        \n","        return masked_losses\n","    \n","    return loss\n","    \n","model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss=masked_loss(x=word_ids), \n","              target_tensors=[tf.keras.Input([None], dtype=tf.int32), \n","                              tf.keras.Input([None], dtype=tf.int32)])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EwMxbXALZQro","outputId":"784152e4-dc5d-403e-c1cd-3d31f67305fa","scrolled":false,"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1585778354149,"user_tz":-120,"elapsed":10784840,"user":{"displayName":"emanuele alessi","photoUrl":"","userId":"08652787951056062162"}}},"source":["steps = len(sentences) // batch_size\n","epochs = 5\n","for epoch in range(epochs):\n","  avg_loss = 0\n","  for step in tqdm.tqdm(range(steps), desc='Epoch ' + str(epoch + 1) + '/' + str(epochs)):\n","      \n","      l = model.train_on_batch(x=tf.keras.preprocessing.sequence.pad_sequences(sentences[step * batch_size: (step + 1) * batch_size], padding='post'), \n","                               y=[tf.keras.preprocessing.sequence.pad_sequences(lemmas[step * batch_size: (step + 1) * batch_size], padding='post'), \n","                                  tf.keras.preprocessing.sequence.pad_sequences(pos[step * batch_size: (step + 1) * batch_size], padding='post')])\n","          \n","      avg_loss += l[0]\n","      \n","      if (step > 0) and step % 500 == 0 or (step == steps - 1):\n","          print('Loss:', avg_loss / step)\n","              \n","  for dataset in test:\n","          y_true_lemma = []\n","          y_true_pos = []\n","          y_pred_lemma = []\n","          y_pred_pos = []\n","          for x, y1, y2 in test[dataset]:\n","              pred_lemma, pred_pos = model.predict(x)\n","              pred_lemma = np.argmax(pred_lemma, axis=-1).reshape(-1)\n","              pred_pos = np.argmax(pred_pos, axis=-1).reshape(-1)\n","              \n","              y_true_lemma += y1\n","              y_pred_lemma += pred_lemma.tolist()\n","              \n","              y_true_pos += y2\n","              y_pred_pos += pred_pos.tolist()\n","          \n","          acc_lemma, acc_pos = accuracy(y_true_lemma, y_pred_lemma), accuracy(y_true_pos, y_pred_pos)\n","              \n","          print(dataset + ' results ')\n","          print('lemma accuracy: ' + str(acc_lemma) + '\\t' + 'pos accuracy: ' + str(acc_pos))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Epoch 1/5:  22%|██▏       | 501/2323 [07:42<29:07,  1.04it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 2.7472714449167253\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 1/5:  43%|████▎     | 1001/2323 [15:01<18:14,  1.21it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 2.142255606532097\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 1/5:  65%|██████▍   | 1501/2323 [22:52<11:56,  1.15it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 1.815761889676253\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 1/5:  86%|████████▌ | 2001/2323 [30:36<04:48,  1.12it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 1.5698080129027367\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 1/5: 100%|██████████| 2323/2323 [35:49<00:00,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 1.4469674629424791\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["senseval2 results \n","lemma accuracy: 0.8156434269857787\tpos accuracy: 0.7481789802289281\n","senseval3 results \n","lemma accuracy: 0.8265656018769175\tpos accuracy: 0.734885399747338\n","semeval2007 results \n","lemma accuracy: 0.7981880662293034\tpos accuracy: 0.7244611059044048\n","semeval2013 results \n","lemma accuracy: 0.8020498152782743\tpos accuracy: 0.6931235847932309\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch 2/5:   0%|          | 0/2323 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["semeval2015 results \n","lemma accuracy: 0.8095238095238095\tpos accuracy: 0.7142857142857143\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 2/5:  22%|██▏       | 501/2323 [07:36<28:43,  1.06it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.5592514248490333\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 2/5:  43%|████▎     | 1001/2323 [14:50<18:45,  1.17it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.5370316023826599\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 2/5:  65%|██████▍   | 1501/2323 [22:43<12:03,  1.14it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.5057698522259791\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 2/5:  86%|████████▌ | 2001/2323 [30:32<04:51,  1.10it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.4668887651599944\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 2/5: 100%|██████████| 2323/2323 [35:44<00:00,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.4469694127998508\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["senseval2 results \n","lemma accuracy: 0.8836281651057926\tpos accuracy: 0.807145334720777\n","senseval3 results \n","lemma accuracy: 0.8922577152138603\tpos accuracy: 0.7922757624977441\n","semeval2007 results \n","lemma accuracy: 0.8637925648234926\tpos accuracy: 0.788191190253046\n","semeval2013 results \n","lemma accuracy: 0.8647360266952687\tpos accuracy: 0.7565248480514837\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch 3/5:   0%|          | 0/2323 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["semeval2015 results \n","lemma accuracy: 0.8609831029185868\tpos accuracy: 0.7922427035330261\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 3/5:  22%|██▏       | 501/2323 [07:33<28:39,  1.06it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.32033428648114204\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 3/5:  43%|████▎     | 1001/2323 [14:45<17:52,  1.23it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.315428119301796\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 3/5:  65%|██████▍   | 1501/2323 [22:30<11:50,  1.16it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.2992503169327974\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 3/5:  86%|████████▌ | 2001/2323 [30:18<04:51,  1.10it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.2745787087250501\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 3/5: 100%|██████████| 2323/2323 [35:34<00:00,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.2625655102014901\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["senseval2 results \n","lemma accuracy: 0.9046132500867152\tpos accuracy: 0.8222337842525147\n","senseval3 results \n","lemma accuracy: 0.907236960837394\tpos accuracy: 0.8184443241292185\n","semeval2007 results \n","lemma accuracy: 0.8856607310215557\tpos accuracy: 0.8131833801936895\n","semeval2013 results \n","lemma accuracy: 0.8870218090811584\tpos accuracy: 0.787033726611846\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch 4/5:   0%|          | 0/2323 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["semeval2015 results \n","lemma accuracy: 0.8740399385560675\tpos accuracy: 0.8133640552995391\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 4/5:  22%|██▏       | 501/2323 [07:41<28:51,  1.05it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.22250076867640017\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 4/5:  43%|████▎     | 1001/2323 [14:53<17:55,  1.23it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.21868399899825453\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 4/5:  65%|██████▍   | 1501/2323 [22:35<11:41,  1.17it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.2051831921065847\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 4/5:  86%|████████▌ | 2001/2323 [30:15<04:44,  1.13it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.18535663773119448\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 4/5: 100%|██████████| 2323/2323 [35:27<00:00,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.1758997002929372\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["senseval2 results \n","lemma accuracy: 0.9172736732570239\tpos accuracy: 0.8329864724245577\n","senseval3 results \n","lemma accuracy: 0.9126511460025266\tpos accuracy: 0.8296336401371593\n","semeval2007 results \n","lemma accuracy: 0.8978444236176195\tpos accuracy: 0.823805060918463\n","semeval2013 results \n","lemma accuracy: 0.8959599570968895\tpos accuracy: 0.800500536288881\n"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch 5/5:   0%|          | 0/2323 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["semeval2015 results \n","lemma accuracy: 0.881336405529954\tpos accuracy: 0.8221966205837173\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 5/5:  22%|██▏       | 501/2323 [07:33<28:45,  1.06it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.16792218124866484\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 5/5:  43%|████▎     | 1001/2323 [14:45<17:51,  1.23it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.16494994891062378\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 5/5:  65%|██████▍   | 1501/2323 [22:29<11:45,  1.16it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.1532962877874573\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 5/5:  86%|████████▌ | 2001/2323 [30:12<04:44,  1.13it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.13644281321018933\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 5/5: 100%|██████████| 2323/2323 [35:23<00:00,  1.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss: 0.12845378027046475\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["senseval2 results \n","lemma accuracy: 0.9198751300728408\tpos accuracy: 0.8459937565036421\n","senseval3 results \n","lemma accuracy: 0.9166215484569572\tpos accuracy: 0.8442519400830175\n","semeval2007 results \n","lemma accuracy: 0.9019056544829741\tpos accuracy: 0.8288034989065917\n","semeval2013 results \n","lemma accuracy: 0.9021570730544631\tpos accuracy: 0.8296984864736027\n","semeval2015 results \n","lemma accuracy: 0.8859447004608295\tpos accuracy: 0.8452380952380952\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5gk19LJ4ZQsI","colab":{}},"source":["model.save('drive/My Drive/AFC/models/multitask.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kwq4G_Ob2Bk4","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uGuJdDoahRFn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}